{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awjans/CopilotForPRsAdoption/blob/main/AIDev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection/Cleaning Overview\n",
        "1. **PR identification**\n",
        "   * Queried GitHub via GraphQL for PRs whose description contained the phrase **‚ÄúGenerated by Copilot‚Äù** or any of the marker tags:\n",
        "\n",
        "     * `copilot:summary`\n",
        "     * `copilot:walkthrough`\n",
        "     * `copilot:poem`\n",
        "     * `copilot:all`\n",
        "\n",
        "2. **Scope**\n",
        "   * Collected **18,256 PRs** from **146 early-adopter repositories** during **March 2023 ‚Äì August 2023**.\n",
        "\n",
        "3. **Control set**\n",
        "   * For the same repositories, gathered **54,188 PRs** that did **not** contain any Copilot marker.\n",
        "   * These served as the **untreated (control) group** for the **RQ2 comparison**.\n",
        "\n",
        "4. **Bot filtering**\n",
        "   * Removed PRs and comments authored by bots using the **high-precision method** of **Golzadeh et al. (2022)**, which included:\n",
        "     * (i) Usernames ending with ‚Äúbot‚Äù\n",
        "     * (ii) A curated list of **527 known bot accounts**\n",
        "\n",
        "5. **Revision extraction (RQ3)**\n",
        "   * From the **18,256 Copilot-generated PRs**, retrieved the full **edit history** of PR descriptions.\n",
        "   * Identified **1,437 revisions** where developers **edited the AI-suggested content**."
      ],
      "metadata": {
        "id": "j4dl0GKtyPQO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ03WzKRQ1bS"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import matplotlib.pyplot as plt\n",
        "import nest_asyncio\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "\n",
        "from dateutil import parser\n",
        "from google.colab import userdata\n",
        "from urllib.parse import urlparse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9b7c674"
      },
      "source": [
        "# **First**, We need to define the URLs of the AIDev Parquet Files that we are intersted in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de61a39b"
      },
      "source": [
        "pull_request_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/all_pull_request.parquet'\n",
        "pr_comments_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/pr_comments.parquet'\n",
        "pr_commits_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/pr_commits.parquet'\n",
        "pr_commit_details_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/pr_commit_details.parquet'\n",
        "pr_reviews_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/pr_reviews.parquet'\n",
        "pr_review_comments_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/pr_review_comments.parquet'\n",
        "pr_task_type_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/pr_task_type.parquet'\n",
        "repository_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/all_repository.parquet'\n",
        "user_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/user.parquet'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Load the Parquet file into a Pandas DataFrame from the file URL.\n",
        "\"\"\"\n",
        "def load_data(url: str):\n",
        "  import pandas as pd # Import pandas inside the function\n",
        "  try:\n",
        "    # For Parquet files:\n",
        "    df = pd.read_parquet(url)\n",
        "\n",
        "    return df\n",
        "  except Exception as e:\n",
        "      print(f\"Error loading data: {e}\")\n",
        "      print(\"Please ensure the URL is correct and the file is publicly accessible.\")\n",
        "      return None # Return None in case of an error"
      ],
      "metadata": {
        "id": "Qcu3bdoFM6UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "818abba5"
      },
      "source": [
        "nest_asyncio.apply()\n",
        "\n",
        "GH_TOKEN = os.environ.get('GITHUB_TOKEN', userdata.get('GITHUB_TOKEN'))\n",
        "\n",
        "async def get_repo_data(repo_url: str):\n",
        "    # Make the Request\n",
        "    print(f'Requesting: {repo_url}')\n",
        "    response = requests.get(repo_url, headers={'Authorization': f'token {GH_TOKEN}'})\n",
        "    response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "    # Process the JSON response\n",
        "    return response.json()\n",
        "\n",
        "\n",
        "def get_repo_created_at(repo_url: str):\n",
        "    \"\"\"\n",
        "    Get the Repository Created At timestamp for the Repo from GitHub the API call.\n",
        "\n",
        "    Args:\n",
        "        repo_url: The GitHub API repository URL.\n",
        "\n",
        "    Returns:\n",
        "        The created_at timestamp if successful, None otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        task = asyncio.create_task(get_repo_data(repo_url))\n",
        "        event_loop = asyncio.get_running_loop()\n",
        "        if event_loop.is_running():\n",
        "          data = event_loop.run_until_complete(task)\n",
        "        else:\n",
        "          data = asyncio.run(task)\n",
        "\n",
        "        # Extract the createdAt value\n",
        "        created_at = data['created_at']\n",
        "        print(f\"Repo: {repo_url}; Created At: {created_at}\")\n",
        "\n",
        "        if created_at:\n",
        "            return pd.to_datetime(created_at)\n",
        "        else:\n",
        "            raise Exception(f\"Error: Could not retrieve createdAt for {repo_url}. Response data: {data}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error during GitHub API request for {repo_url}: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Second**, We need to load the data from the URLs (15s)"
      ],
      "metadata": {
        "id": "CKy9xnAeb1p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pull_request = load_data(pull_request_file_url)\n",
        "pr_comments = load_data(pr_comments_file_url)\n",
        "pr_commits = load_data(pr_commits_file_url)\n",
        "pr_commit_details = load_data(pr_commit_details_file_url)\n",
        "pr_reviews = load_data(pr_reviews_file_url)\n",
        "pr_review_comments = load_data(pr_review_comments_file_url)\n",
        "pr_task_type = load_data(pr_task_type_file_url)\n",
        "repository = load_data(repository_file_url)\n",
        "user = load_data(user_file_url)"
      ],
      "metadata": {
        "id": "YAPFfpktRJkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Copy of Pull_Requests & Data Cleaning\n",
        "\n",
        "1. **Copies DataFrames:** It creates copies of the pull_request and repository DataFrames and assigns them to metrics and repos respectively. This is a good practice to avoid modifying the original loaded data.\n",
        "2. **Renames Columns:** It renames the 'id' column to 'pr_id' in the metrics DataFrame and to 'repo_id' in the repos DataFrame. This is done to prepare for merging these DataFrames later.\n",
        "3. **Filters Open Pull Requests:** It removes pull requests that are still open by filtering out rows where the 'closed_at' column has a missing value (NaN).\n",
        "4. **Converts Timestamps:** It converts the 'created_at' and 'closed_at' columns in the metrics DataFrame to datetime objects. This allows for easier time-based calculations.\n",
        "5. **Filters Repositories:** It removes repositories from the repos DataFrame that do not have any closed pull requests in the metrics DataFrame.\n",
        "6. **Gets Repository Creation Dates:** For the remaining repositories, it calls the get_repo_created_at function (defined in a previous cell) to fetch the creation date of each repository from the GitHub API and stores it in a new column 'repo_created_at'.\n",
        "7. **Filters Repositories with Creation Dates:** It removes repositories where the 'repo_created_at' could not be retrieved."
      ],
      "metadata": {
        "id": "67cBtszBeJC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Old\n",
        "\n",
        "# metrics = pull_request.copy()\n",
        "# repos = repository.copy()\n",
        "\n",
        "# # Rename 'id' to 'pr_id' for joining\n",
        "# metrics = metrics.rename(columns={'id': 'pr_id'})\n",
        "# repos = repos.rename(columns={'id': 'repo_id'})\n",
        "\n",
        "# # Remove Open Pull Requests (closed_at is None)\n",
        "# print(f\"Number of Pull Requests: {len(metrics)}\")\n",
        "# metrics = metrics[metrics['closed_at'].notna()]\n",
        "# print(f\"Number of Closed Pull Requests: {len(metrics)}\")\n",
        "\n",
        "# # Convert Timestamps\n",
        "# metrics['created_at'] = pd.to_datetime(metrics['created_at'])\n",
        "# metrics['closed_at'] = pd.to_datetime(metrics['closed_at'])\n",
        "\n",
        "# # Remove Repositories that do not have a Pull Request\n",
        "# print(f\"Number of Repositories: {len(repos)}\")\n",
        "# repos = repos[repos['repo_id'].isin(metrics['repo_id'])]\n",
        "# print(f\"Number of Repositories with Pull Requests: {len(repos)}\")\n",
        "# repos['repo_created_at'] = repos.apply(lambda row: get_repo_created_at(row['url']), axis=1)\n",
        "# repos = repos.dropna(subset=['created_at'])\n",
        "# print(f\"Number of Repositories with Pull Requests that are Active: {len(repos)}\")"
      ],
      "metadata": {
        "id": "QuyRRwfJc30t",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, random, requests, pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Copy raw data\n",
        "metrics = pull_request.copy()\n",
        "repos = repository.copy()\n",
        "\n",
        "# === BASIC CLEANUP ===\n",
        "metrics = metrics.rename(columns={'id': 'pr_id'})\n",
        "repos = repos.rename(columns={'id': 'repo_id'})\n",
        "\n",
        "print(f\"Total PRs before filtering: {len(metrics):,}\")\n",
        "metrics = metrics[metrics['closed_at'].notna()]\n",
        "print(f\"Closed PRs retained: {len(metrics):,}\")\n",
        "\n",
        "metrics['created_at'] = pd.to_datetime(metrics['created_at'], errors='coerce')\n",
        "metrics['closed_at'] = pd.to_datetime(metrics['closed_at'], errors='coerce')\n",
        "\n",
        "print(f\"Total repos before filtering: {len(repos):,}\")\n",
        "repos = repos[repos['repo_id'].isin(metrics['repo_id'])]\n",
        "print(f\"Repos with ‚â•1 PR: {len(repos):,}\")\n",
        "\n",
        "# === ADD: SMALL-SUBSET TEST MODE ===\n",
        "# Toggle to True for testing on limited data before full run\n",
        "TEST_MODE = True\n",
        "if TEST_MODE:\n",
        "    # randomly sample e.g. 10 repos to stay under rate limits\n",
        "    test_repo_ids = repos['repo_id'].sample(min(50, len(repos)), random_state=42)\n",
        "    metrics = metrics[metrics['repo_id'].isin(test_repo_ids)]\n",
        "    repos = repos[repos['repo_id'].isin(test_repo_ids)]\n",
        "    print(f\"[TEST MODE] Restricting to {len(repos)} repos and {len(metrics)} PRs\")\n",
        "\n",
        "# === DEFINE SAFE REQUEST WRAPPER ===\n",
        "GITHUB_TOKEN = os.environ.get(\"GITHUB_TOKEN\")  # set earlier with your PAT\n",
        "\n",
        "def safe_get(url, sleep_base=1.0, retries=3):\n",
        "    \"\"\"GET with retry, error handling, and rate-limit backoff.\"\"\"\n",
        "    headers = {'Authorization': f'token {GITHUB_TOKEN}',\n",
        "               'Accept': 'application/vnd.github+json'}\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            r = requests.get(url, headers=headers)\n",
        "            # --- Rate limit exceeded ---\n",
        "            if r.status_code == 403 and 'X-RateLimit-Remaining' in r.headers and r.headers['X-RateLimit-Remaining'] == '0':\n",
        "                reset_time = int(r.headers.get('X-RateLimit-Reset', time.time()+60))\n",
        "                sleep_for = max(reset_time - time.time(), 30)\n",
        "                print(f\"[RATE-LIMIT] Sleeping {sleep_for/60:.1f} min until reset ‚Ä¶\")\n",
        "                time.sleep(sleep_for + 1)\n",
        "                continue\n",
        "\n",
        "            # --- Success / known cases ---\n",
        "            if r.status_code in (200, 204, 404):\n",
        "                return r\n",
        "            else:\n",
        "                print(f\"[WARN] {r.status_code} on {url}\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"[ERROR] Request failed: {e}\")\n",
        "        # --- backoff ---\n",
        "        time.sleep(sleep_base * (2 ** attempt) + random.uniform(0, 1))\n",
        "    return None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKaF2xpBcvJd",
        "outputId": "a0b9aed1-715f-4e5c-bd5c-18f1665e9d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total PRs before filtering: 932,791\n",
            "Closed PRs retained: 859,927\n",
            "Total repos before filtering: 116,211\n",
            "Repos with ‚â•1 PR: 91,526\n",
            "[TEST MODE] Restricting to 50 repos and 288 PRs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(metrics.head())\n",
        "display(repos.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "collapsed": true,
        "id": "ODq_0xOtetTr",
        "outputId": "e54923a1-742f-470f-d2b2-a8e6ea214800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           pr_id  number                                              title  \\\n",
              "7444  3121122850       4  „ÄêBackend„ÄëImplement NestJS Todo API with full C...   \n",
              "7445  3121123322       5  „ÄêFrontend„ÄëComplete Next.js Todo UI Implementat...   \n",
              "7455  3121217396       6  „ÄêBackend„ÄëComplete NestJS Todo API implementati...   \n",
              "7456  3121220491       7  „ÄêFrontend„ÄëImplement Next.js Todo UI with compl...   \n",
              "8125  3209759530       2  üîß Implement Student Tracker Admin System ‚Äî Com...   \n",
              "\n",
              "                                                   body    agent    user_id  \\\n",
              "7444  This PR implements a complete NestJS Todo API ...  Copilot  198982749   \n",
              "7445  This PR implements a complete, modern Todo man...  Copilot  198982749   \n",
              "7455  This PR implements a complete Todo management ...  Copilot  198982749   \n",
              "7456  This PR implements a complete Todo management ...  Copilot  198982749   \n",
              "8125  This PR implements a comprehensive Flask web a...  Copilot  198982749   \n",
              "\n",
              "         user   state                created_at                 closed_at  \\\n",
              "7444  Copilot  closed 2025-06-05 12:52:44+00:00 2025-06-05 13:18:25+00:00   \n",
              "7445  Copilot  closed 2025-06-05 12:52:53+00:00 2025-06-05 13:18:14+00:00   \n",
              "7455  Copilot  closed 2025-06-05 13:19:15+00:00 2025-06-05 20:51:36+00:00   \n",
              "7456  Copilot  closed 2025-06-05 13:19:58+00:00 2025-06-05 20:58:16+00:00   \n",
              "8125  Copilot  closed 2025-07-07 17:22:39+00:00 2025-07-07 17:37:52+00:00   \n",
              "\n",
              "                 merged_at       repo_id  \\\n",
              "7444                  None  9.967673e+08   \n",
              "7445                  None  9.967673e+08   \n",
              "7455  2025-06-05T20:51:36Z  9.967673e+08   \n",
              "7456  2025-06-05T20:58:16Z  9.967673e+08   \n",
              "8125  2025-07-07T17:37:52Z  1.015549e+09   \n",
              "\n",
              "                                               repo_url  \\\n",
              "7444  https://api.github.com/repos/yasu-programming/...   \n",
              "7445  https://api.github.com/repos/yasu-programming/...   \n",
              "7455  https://api.github.com/repos/yasu-programming/...   \n",
              "7456  https://api.github.com/repos/yasu-programming/...   \n",
              "8125  https://api.github.com/repos/galshohat/student...   \n",
              "\n",
              "                                               html_url  \n",
              "7444  https://github.com/yasu-programming/test-todo-...  \n",
              "7445  https://github.com/yasu-programming/test-todo-...  \n",
              "7455  https://github.com/yasu-programming/test-todo-...  \n",
              "7456  https://github.com/yasu-programming/test-todo-...  \n",
              "8125  https://github.com/galshohat/student-manage-ex...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82704344-ac6c-4201-b795-82533449c029\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pr_id</th>\n",
              "      <th>number</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>agent</th>\n",
              "      <th>user_id</th>\n",
              "      <th>user</th>\n",
              "      <th>state</th>\n",
              "      <th>created_at</th>\n",
              "      <th>closed_at</th>\n",
              "      <th>merged_at</th>\n",
              "      <th>repo_id</th>\n",
              "      <th>repo_url</th>\n",
              "      <th>html_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7444</th>\n",
              "      <td>3121122850</td>\n",
              "      <td>4</td>\n",
              "      <td>„ÄêBackend„ÄëImplement NestJS Todo API with full C...</td>\n",
              "      <td>This PR implements a complete NestJS Todo API ...</td>\n",
              "      <td>Copilot</td>\n",
              "      <td>198982749</td>\n",
              "      <td>Copilot</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-06-05 12:52:44+00:00</td>\n",
              "      <td>2025-06-05 13:18:25+00:00</td>\n",
              "      <td>None</td>\n",
              "      <td>9.967673e+08</td>\n",
              "      <td>https://api.github.com/repos/yasu-programming/...</td>\n",
              "      <td>https://github.com/yasu-programming/test-todo-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7445</th>\n",
              "      <td>3121123322</td>\n",
              "      <td>5</td>\n",
              "      <td>„ÄêFrontend„ÄëComplete Next.js Todo UI Implementat...</td>\n",
              "      <td>This PR implements a complete, modern Todo man...</td>\n",
              "      <td>Copilot</td>\n",
              "      <td>198982749</td>\n",
              "      <td>Copilot</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-06-05 12:52:53+00:00</td>\n",
              "      <td>2025-06-05 13:18:14+00:00</td>\n",
              "      <td>None</td>\n",
              "      <td>9.967673e+08</td>\n",
              "      <td>https://api.github.com/repos/yasu-programming/...</td>\n",
              "      <td>https://github.com/yasu-programming/test-todo-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7455</th>\n",
              "      <td>3121217396</td>\n",
              "      <td>6</td>\n",
              "      <td>„ÄêBackend„ÄëComplete NestJS Todo API implementati...</td>\n",
              "      <td>This PR implements a complete Todo management ...</td>\n",
              "      <td>Copilot</td>\n",
              "      <td>198982749</td>\n",
              "      <td>Copilot</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-06-05 13:19:15+00:00</td>\n",
              "      <td>2025-06-05 20:51:36+00:00</td>\n",
              "      <td>2025-06-05T20:51:36Z</td>\n",
              "      <td>9.967673e+08</td>\n",
              "      <td>https://api.github.com/repos/yasu-programming/...</td>\n",
              "      <td>https://github.com/yasu-programming/test-todo-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7456</th>\n",
              "      <td>3121220491</td>\n",
              "      <td>7</td>\n",
              "      <td>„ÄêFrontend„ÄëImplement Next.js Todo UI with compl...</td>\n",
              "      <td>This PR implements a complete Todo management ...</td>\n",
              "      <td>Copilot</td>\n",
              "      <td>198982749</td>\n",
              "      <td>Copilot</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-06-05 13:19:58+00:00</td>\n",
              "      <td>2025-06-05 20:58:16+00:00</td>\n",
              "      <td>2025-06-05T20:58:16Z</td>\n",
              "      <td>9.967673e+08</td>\n",
              "      <td>https://api.github.com/repos/yasu-programming/...</td>\n",
              "      <td>https://github.com/yasu-programming/test-todo-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8125</th>\n",
              "      <td>3209759530</td>\n",
              "      <td>2</td>\n",
              "      <td>üîß Implement Student Tracker Admin System ‚Äî Com...</td>\n",
              "      <td>This PR implements a comprehensive Flask web a...</td>\n",
              "      <td>Copilot</td>\n",
              "      <td>198982749</td>\n",
              "      <td>Copilot</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-07 17:22:39+00:00</td>\n",
              "      <td>2025-07-07 17:37:52+00:00</td>\n",
              "      <td>2025-07-07T17:37:52Z</td>\n",
              "      <td>1.015549e+09</td>\n",
              "      <td>https://api.github.com/repos/galshohat/student...</td>\n",
              "      <td>https://github.com/galshohat/student-manage-ex...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82704344-ac6c-4201-b795-82533449c029')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82704344-ac6c-4201-b795-82533449c029 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82704344-ac6c-4201-b795-82533449c029');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0dae8175-4ffa-4640-939b-571b628e5d40\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0dae8175-4ffa-4640-939b-571b628e5d40')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0dae8175-4ffa-4640-939b-571b628e5d40 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          repo_id                                                url  \\\n",
              "9589   1015549410  https://api.github.com/repos/galshohat/student...   \n",
              "10140   850326047  https://api.github.com/repos/hossain-khan/andr...   \n",
              "11343  1005234937  https://api.github.com/repos/laurance18/cm3l-r...   \n",
              "14618   929124041  https://api.github.com/repos/sohamw03/knowledg...   \n",
              "16080   996767281  https://api.github.com/repos/yasu-programming/...   \n",
              "\n",
              "          license                        full_name    language  forks  stars  \n",
              "9589         None      galshohat/student-manage-ex        HTML    0.0    0.0  \n",
              "10140         MIT  hossain-khan/android-keep-alive      Kotlin    2.0   21.0  \n",
              "11343         MIT         laurance18/cm3l-research        None    0.0    0.0  \n",
              "14618  Apache-2.0           sohamw03/knowledge_net  TypeScript    0.0    4.0  \n",
              "16080        None   yasu-programming/test-todo-app  TypeScript    0.0    0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54260283-9d8a-4c96-bb6c-db676aa5c091\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>repo_id</th>\n",
              "      <th>url</th>\n",
              "      <th>license</th>\n",
              "      <th>full_name</th>\n",
              "      <th>language</th>\n",
              "      <th>forks</th>\n",
              "      <th>stars</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9589</th>\n",
              "      <td>1015549410</td>\n",
              "      <td>https://api.github.com/repos/galshohat/student...</td>\n",
              "      <td>None</td>\n",
              "      <td>galshohat/student-manage-ex</td>\n",
              "      <td>HTML</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10140</th>\n",
              "      <td>850326047</td>\n",
              "      <td>https://api.github.com/repos/hossain-khan/andr...</td>\n",
              "      <td>MIT</td>\n",
              "      <td>hossain-khan/android-keep-alive</td>\n",
              "      <td>Kotlin</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11343</th>\n",
              "      <td>1005234937</td>\n",
              "      <td>https://api.github.com/repos/laurance18/cm3l-r...</td>\n",
              "      <td>MIT</td>\n",
              "      <td>laurance18/cm3l-research</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14618</th>\n",
              "      <td>929124041</td>\n",
              "      <td>https://api.github.com/repos/sohamw03/knowledg...</td>\n",
              "      <td>Apache-2.0</td>\n",
              "      <td>sohamw03/knowledge_net</td>\n",
              "      <td>TypeScript</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16080</th>\n",
              "      <td>996767281</td>\n",
              "      <td>https://api.github.com/repos/yasu-programming/...</td>\n",
              "      <td>None</td>\n",
              "      <td>yasu-programming/test-todo-app</td>\n",
              "      <td>TypeScript</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54260283-9d8a-4c96-bb6c-db676aa5c091')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54260283-9d8a-4c96-bb6c-db676aa5c091 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54260283-9d8a-4c96-bb6c-db676aa5c091');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-835be7df-8b77-4135-9cb1-f050c0200f20\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-835be7df-8b77-4135-9cb1-f050c0200f20')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-835be7df-8b77-4135-9cb1-f050c0200f20 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(repos\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"repo_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 69756132,\n        \"min\": 850326047,\n        \"max\": 1015549410,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          850326047,\n          996767281,\n          1005234937\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"https://api.github.com/repos/hossain-khan/android-keep-alive\",\n          \"https://api.github.com/repos/yasu-programming/test-todo-app\",\n          \"https://api.github.com/repos/laurance18/cm3l-research\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"license\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Apache-2.0\",\n          \"MIT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"hossain-khan/android-keep-alive\",\n          \"yasu-programming/test-todo-app\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"language\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"HTML\",\n          \"Kotlin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"forks\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8944271909999161,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stars\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.1104335791443,\n        \"min\": 0.0,\n        \"max\": 21.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          21.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount drive to save Dataset for all of our access"
      ],
      "metadata": {
        "id": "jA6SGbhQZhLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXf5zM0UZf20",
        "outputId": "c00ec89b-3a8b-4dec-e941-c54f0496c62b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save initial processed Dataset (no need to re-run this every time)"
      ],
      "metadata": {
        "id": "sVs4gjRhZ4zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.to_pickle(\"/content/drive/MyDrive/AIDev_shared/metrics_cleaned.pkl\")\n",
        "repos.to_pickle(\"/content/drive/MyDrive/AIDev_shared/repos_cleaned.pkl\")"
      ],
      "metadata": {
        "id": "WOunph6PZrOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FOR TESTING\n",
        "metrics.to_pickle(\"/content/drive/MyDrive/AIDev_shared/metrics_TEST.pkl\")\n",
        "repos.to_pickle(\"/content/drive/MyDrive/AIDev_shared/repos_TEST.pkl\")"
      ],
      "metadata": {
        "id": "qy077Rz2drsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reload dataset (this can be ran every time)"
      ],
      "metadata": {
        "id": "YUGl3g1aaApG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "metrics = pd.read_pickle(\"/content/drive/MyDrive/AIDev_shared/metrics_cleaned.pkl\")\n",
        "repos = pd.read_pickle(\"/content/drive/MyDrive/AIDev_shared/repos_cleaned.pkl\")\n",
        "print(\"‚úÖ Loaded shared cached cleaned dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxAKR0tjaA7d",
        "outputId": "42b42e63-231d-4c27-8fdd-863ec16ea09f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded shared cached cleaned dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FOR TESTING\n",
        "import pandas as pd\n",
        "metrics = pd.read_pickle(\"/content/drive/MyDrive/AIDev_shared/metrics_TEST.pkl\")\n",
        "repos = pd.read_pickle(\"/content/drive/MyDrive/AIDev_shared/repos_TEST.pkl\")\n",
        "print(\"‚úÖ Loaded TEST shared cached cleaned dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz6YPZpJdyTT",
        "outputId": "bc27e075-7e1a-4d9a-d028-9e43277e8668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded TEST shared cached cleaned dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we decide to update this dataset again or for frequent updates-- use this to prevent overwriting"
      ],
      "metadata": {
        "id": "8VrCLkuWaX_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "tag = date.today().isoformat()\n",
        "metrics.to_pickle(f\"/content/drive/MyDrive/AIDev_shared/metrics_{tag}.pkl\")\n",
        "repos.to_pickle(f\"/content/drive/MyDrive/AIDev_shared/metrics_{tag}.pkl\")"
      ],
      "metadata": {
        "id": "hfQlplV8aXD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Third**, Gather the covariant variables\n",
        "\n",
        "## PR Variables\n",
        "\n",
        "1. **additions:** The # of added LOC by a PR\n",
        "2. **deletions:** The # of deleted LOC by a PR\n",
        "3. **prSize:** The total number of added and deleted LOC by a PR (additions + deletions)\n",
        "4. **purpose:** The purpose of a PR, i.e., bug, document, and feature. Simple keyword search in the title/body ('fix', 'bug', 'doc', ‚Ä¶).\n",
        "5. **changedFiles:** The # of files changed by a PR\n",
        "6. **commitsTotalCount:** The # of commits involved in a PR\n",
        "7. **bodyLength**: Length of the PR body (in characters).\n",
        "8. **prExperience:** The # of prior PRs that were submitted by the PR author (author‚Äôs prior PR count). Query the author‚Äôs PR history in the same repo and count PRs created before the current one.\n",
        "9. **isMember:** Whether or not the author is a member or outside collaborator (True/False).\n",
        "10. **commentsTotalCount:** The # of comments left on a PR\n",
        "11. **authorComments:** The # of comments left by the PR author\n",
        "12. **reviewersComments:** The # of comments left by the reviewers who participate in the disucssion\n",
        "13. **reviewersTotalCount:** The # of developers who participate in the discussion (excluding author).\n",
        "14. **repoAge:** Time interval between the repository creation time and PR creation time in days.\n",
        "15. **state**: State of the pull request (MERGED or CLOSED).\n",
        "16. **reviewTime**: Time taken to review the PR (in hours, floating point, no rounding).\n",
        "\n",
        "## Project variables\n",
        "\n",
        "17. **repoLanguage:** Programming language of the repository (e.g., Python, PHP, TypeScript, Vue). *[I'm assuming its the top language as there is only one]*\n",
        "18. **forkCount:** The # of forks that a repository has\n",
        "19. **stargazerCount:** The # of stargazers that a repository has.\n",
        "\n",
        "## Treatment variables\n",
        "\n",
        "20. **With Copilot for PRs:** Whether or not a PR is generated by Copilot for PRs (binary)\n",
        "\n",
        "## Outcome variables\n",
        "\n",
        "21. **Review time (reviewTime):** Time interval between the PR creation time and closed time in hours\n",
        "22. **Is merged (state):** Whether or not a PR is merged (binary)\n",
        "\n"
      ],
      "metadata": {
        "id": "a30SFFhZXgy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PR Variables"
      ],
      "metadata": {
        "id": "xANcFKyCb9Fm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34d51076"
      },
      "source": [
        "1. **additions:** The # of added LOC by a PR\n",
        "2. **deletions:** The # of deleted LOC by a PR\n",
        "3. **prSize:** The total number of added and deleted LOC by a PR (additions + deletions)\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "In the notebook (e.g., CollectCopilot4prs.ipynb), the `additions` and `deletions` values are extracted directly from the GitHub API response for each PR: `pr['node']['additions']` and `pr['node']['deletions']`. The GraphQL query for PRs includes the fields, so the value is as reported by GitHub. `prSize = additions + deletions`\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "In the `pr_commit_details` DataFrame, we use the `additions` and `deletions` fields. We sum them for `prSize`. Alternatively, the dataset also has`changes` which represents prSize but we chose to perform the sum ourselves.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['additions', 'deletions', 'prSize'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding LOC metrics: {len(metrics):,}\")\n",
        "\n",
        "# Get the sums of the columns we are interested in\n",
        "pr_commit_LOC = (pr_commit_details.groupby(['pr_id'])\n",
        "                                  .sum(['additions', 'deletions', 'changes'])\n",
        "                                  .reset_index())\n",
        "\n",
        "# Rename the sum columns to what we want\n",
        "pr_commit_LOC = (pr_commit_LOC.rename(columns={'changes': 'prSize'}))\n",
        "\n",
        "# Drop the extraneous columns\n",
        "pr_commit_LOC = pr_commit_LOC.drop(columns=['commit_stats_total', 'commit_stats_additions', 'commit_stats_deletions'])\n",
        "\n",
        "# Merge the Dataframes with a left join\n",
        "metrics = pd.merge(metrics, pr_commit_LOC, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage collect the temporary Dataframe\n",
        "pr_commit_LOC = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['additions'] = metrics['additions'].fillna(0).astype(int)\n",
        "metrics['deletions'] = metrics['deletions'].fillna(0).astype(int)\n",
        "metrics['prSize'] = metrics['prSize'].fillna(0).astype(int)\n",
        "\n",
        "print(f\"Number of PRs after adding LOC metrics: {len(metrics):,}\")"
      ],
      "metadata": {
        "id": "nj9typbGIcI2",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7e2971-c502-478f-ad13-2a65ee632f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding LOC metrics: 288\n",
            "Number of PRs after adding LOC metrics: 288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **purpose:** The purpose of a PR, i.e., bug, document, and feature. Simple keyword search in the title/body ('fix', 'bug', 'doc', ‚Ä¶).\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "In `CollectCopilot4prs.ipynb`, the code uses `np.select` with conditions based on the PR's title and body content to assign \"Bug\", \"Document\", or \"Feature\" as the purpose. This is a simple rule-based classification:\n",
        "\n",
        "- If the title/body contains keywords for bugs (e.g., \"fix\", \"bug\"), it's labeled \"Bug\".\n",
        "- If it contains documentation keywords (e.g., \"doc\"), it's labeled \"Document\".\n",
        "- Otherwise, it's labeled \"Feature\".\n",
        "\n",
        "\n",
        "**Our approach:**\n",
        "\n",
        "The `title` and `body` columns are part of the initial dataset that was loaded into the pull_request (`all_pull_request.parquet`) DataFrame.\n"
      ],
      "metadata": {
        "id": "_9ULLRD1eVyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['purpose'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before calculating purpose: {len(metrics):,}\")\n",
        "\n",
        "# Combine title and body for keyword search, handling potential None values\n",
        "metrics['title_body'] = metrics['title'].fillna('') + ' ' + metrics['body'].fillna('')\n",
        "\n",
        "# Define conditions and choices for np.select\n",
        "conditions = [\n",
        "    metrics['title_body'].str.contains('fix|bug', case=False, na=False),\n",
        "    metrics['title_body'].str.contains('doc', case=False, na=False)\n",
        "]\n",
        "choices = ['fix', 'doc']\n",
        "\n",
        "# Apply np.select to determine purpose\n",
        "metrics['purpose'] = np.select(conditions, choices, default='feat')\n",
        "\n",
        "# Drop the temporary combined column\n",
        "metrics = metrics.drop(columns=['title_body'])\n",
        "\n",
        "print(f\"Number of PRs after calculating purpose: {len(metrics):,}\")"
      ],
      "metadata": {
        "id": "Hc2sYaVwFPdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9a8a2bf-b6b3-4fea-d5a6-a5ba19c4d2c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before calculating purpose: 288\n",
            "Number of PRs after calculating purpose: 288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c02810ce"
      },
      "source": [
        "5. **changedFiles:** The # of files changed by a PR\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "The `changedFiles` field is extracted directly from the GitHub API for each pull request. In the code (e.g., `in CollectCopilot4prs.ipynb`), it is accessed as: `pr['node']['changedFiles']`.\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "\n",
        "This variable is calculated from the `pr_commit_details` DataFrame, steps include:\n",
        "\n",
        "- Identify the PR identifier: The code uses `groupby(['pr_id', 'filename'])` which implicitly identifies each PR by its `pr_id`.\n",
        "- Locate the file-level change records: It operates on the `pr_commit_details` DataFrame, which contains the file-level change records.\n",
        "- Collect all rows belonging to the same PR: The `groupby(['pr_id', 'filename'])` operation groups all rows for a specific PR together.\n",
        "- Count the number of unique filenames for each `pr_id` across all its commits."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['changedFiles'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding changedFiles: {len(metrics):,}\")\n",
        "\n",
        "# Count the number of Files changed and change the column name to what we want\n",
        "pr_files_changed = (pr_commit_details.groupby(['pr_id', 'filename'])\n",
        "                                     .size()\n",
        "                                     .groupby(['pr_id'])\n",
        "                                     .size()\n",
        "                                     .reset_index(name='changedFiles'))\n",
        "\n",
        "# Merge the Dataframes with a left join\n",
        "metrics = pd.merge(metrics, pr_files_changed, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframe\n",
        "pr_files_changed = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['changedFiles'] = metrics['changedFiles'].fillna(0).astype(int)\n",
        "\n",
        "print(f\"Number of PRs after adding changedFiles: {len(metrics):,}\")"
      ],
      "metadata": {
        "id": "YwnUjWn9FPY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ebf8893-eeed-40bc-bd7b-f0008c0e3b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding changedFiles: 288\n",
            "Number of PRs after adding changedFiles: 288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **commitsTotalCount:** The # of commits involved in a PR\n",
        "\n",
        "\n",
        "**Xiao, 2024:**\n",
        "\n",
        "Fetched from GitHub‚Äôs GraphQL API by querying the PR‚Äôs‚ÄØ`commits { totalCount }` field.\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "The `pr_commit_details` table contains a `sha` column (the commit hash) and a `pr_id` column that links each commit to its pull request. Count every distinct `sha` in the entire table. Group by `pr_id` and count distinct `sha` values for each group.\n"
      ],
      "metadata": {
        "id": "xxZIoTx8fiCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['commitsTotalCount'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding commitsTotalCount: {len(metrics):,}\")\n",
        "\n",
        "# Calculate the number of unique commits for each Pull Request from pr_commit_details\n",
        "# Group by pr_id and count the number of unique sha values\n",
        "pr_commits_count = pr_commit_details.groupby('pr_id')['sha'].nunique().reset_index(name='commitsTotalCount')\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, pr_commits_count, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframe\n",
        "pr_commits_count = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['commitsTotalCount'] = metrics['commitsTotalCount'].fillna(0).astype(int)\n",
        "\n",
        "print(f\"Number of PRs after adding commitsTotalCount: {len(metrics):,}\")"
      ],
      "metadata": {
        "id": "vOyzUxnHFPUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3416b321-246a-4065-9c77-29e84f269efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding commitsTotalCount: 288\n",
            "Number of PRs after adding commitsTotalCount: 288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **bodyLength:** The length of a PR description\n",
        "\n",
        "**Xiao, 2024:**\n",
        "\n",
        "Query each PR with `pullRequest { body }`. Take the returned text and compute its character count (e.g., len(body)). Record that count as the value of description length.\n",
        "\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "In the `pull_request` DataFrame, calculate the character length of the `body` column.\n"
      ],
      "metadata": {
        "id": "Ed6fS14afxfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['bodyLength'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding bodyLength: {len(metrics):,}\")\n",
        "\n",
        "# Get the Length of the Body of the Pull Request\n",
        "metrics['bodyLength'] = metrics['body'].str.len()\n",
        "\n",
        "print(f\"Number of PRs after adding bodyLength: {len(metrics):,}\")"
      ],
      "metadata": {
        "id": "OZYyz-mVFPPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82448453-d3e8-4ea2-f974-594002cc3b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding bodyLength: 288\n",
            "Number of PRs after adding bodyLength: 288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. **prExperience:** The # of prior PRs that were submitted by the PR author (author‚Äôs prior PR count). Query the author‚Äôs PR history in the same repo and count PRs created before the current one.\n",
        "\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "For every pull request the study queries GitHub‚Äôs GraphQL API and extracts the author.login (or author.id) and the repository identifier (repository.id). Using the same API they request all pull requests belonging to the same repository.id whose author.login matches the author of the target PR. Each of these PRs includes its createdAt timestamp. The list is filtered to keep only those PRs whose createdAt value is earlier than the createdAt timestamp of the target PR. The number of remaining PRs is taken as an integer count.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "- Extract the author's login from the `user` column.\n",
        "- Sorts the metrics DataFrame by `repo_id`, `author_login`, and the PR creation time (`created_at`).\n",
        "- Groups the sorted DataFrame by both `repo_id` and `author_login`.\n",
        "- Within each group (for each unique author in each unique repository), it uses the `.cumcount()` method. `cumcount()` assigns a sequential number starting from 0 to each row within the group based on the current order (which is sorted by `created_at`).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JQyVdlFCf2yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['prExperience'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding prExperience: {len(metrics):,}\")\n",
        "\n",
        "# Extract the author's login from the 'user' column and store it in a new column 'author_login'\n",
        "metrics['author_login'] = metrics['user'].astype(str).str.strip()\n",
        "\n",
        "# Drop rows where 'repo_id' or 'created_at' are missing, as these are needed for sorting and calculation\n",
        "metrics = metrics.dropna(subset=['repo_id', 'created_at'])\n",
        "\n",
        "# Sort the DataFrame by 'repo_id', 'author_login', and 'created_at' in ascending order--This is crucial for correctly calculating the cumulative count of PRs for each author within each repository.\n",
        "metrics = metrics.sort_values(['repo_id', 'author_login', 'created_at'])\n",
        "\n",
        "# Calculate the cumulative count of PRs for each author within each repository.\n",
        "# The `groupby(['repo_id', 'author_login'])` groups the DataFrame by repository and author.\n",
        "# The `cumcount()` method then calculates the number of previous PRs for each row within those groups.\n",
        "metrics['prExperience'] = (\n",
        "    metrics.groupby(['repo_id', 'author_login'])\n",
        "           .cumcount()\n",
        "           .astype('Int64')\n",
        ")\n",
        "\n",
        "print(f\"Number of PRs after adding bodyLength: {len(metrics):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS8q-30-icdf",
        "outputId": "8ac75241-3fdd-4ac3-e868-cfbf8b5b4da7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding prExperience: 288\n",
            "Number of PRs after adding bodyLength: 288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. **isMember:** Whether or not the author is a member or outside collaborator (True/False).\n",
        "\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "- For each PR the study calls GitHub‚Äôs GraphQL API and retrieves the author‚Äôs association with the repository (the `authorAssociation` field).\n",
        "- If the returned association is `MEMBER` or `OWNER`, the flag is set to‚ÄØ1; otherwise (e.g., `CONTRIBUTOR`, `NONE`, or an external collaborator) it is set to‚ÄØ0.\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "Followed the same approach as Xiao 2024."
      ],
      "metadata": {
        "id": "IhSC6qwXf95V"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "b205b222",
        "outputId": "560aa25b-31a8-4dc3-9458-2ac618dc8e8a"
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "import time\n",
        "\n",
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "# Only drop the final 'isMember' column if it exists\n",
        "metrics = metrics.drop(columns=['isMember'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding isMember: {len(metrics):,}\")\n",
        "\n",
        "\n",
        "# Ensure you have your GitHub Token set up in Colab Secrets as 'GITHUB_TOKEN'\n",
        "GH_TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "if not GH_TOKEN:\n",
        "    raise RuntimeError(\"‚ùå Missing GITHUB_TOKEN in Colab Secrets.\")\n",
        "\n",
        "def get_author_association(repo_owner: str, repo_name: str, pr_number: int, token: str) -> str:\n",
        "    \"\"\"Fetches the authorAssociation for a PR using GitHub GraphQL API.\"\"\"\n",
        "    query = \"\"\"\n",
        "    query($owner: String!, $repo: String!, $pr: Int!) {\n",
        "      repository(owner: $owner, name: $repo) {\n",
        "        pullRequest(number: $pr) {\n",
        "          authorAssociation\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    \"\"\"\n",
        "    variables = {\n",
        "        \"owner\": repo_owner,\n",
        "        \"repo\": repo_name,\n",
        "        \"pr\": pr_number\n",
        "    }\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {token}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    # Implement basic rate limit handling and retry\n",
        "    for attempt in range(3): # Retry up to 3 times\n",
        "        try:\n",
        "            response = requests.post(\"https://api.github.com/graphql\", json={'query': query, 'variables': variables}, headers=headers)\n",
        "            response.raise_for_status() # Raise an HTTPError for bad responses\n",
        "            data = response.json()\n",
        "\n",
        "            # Check for GraphQL errors\n",
        "            if 'errors' in data:\n",
        "                print(f\"GraphQL errors for PR {pr_number} in {repo_owner}/{repo_name}: {data['errors']}\")\n",
        "                # Check for rate limit exceeded error within GraphQL response\n",
        "                for error in data['errors']:\n",
        "                    if error.get('type') == 'RATE_LIMITED':\n",
        "                         print(\"[RATE-LIMITED] Retrying after a delay...\")\n",
        "                         time.sleep(60) # Wait for a minute before retrying\n",
        "                         break # Exit the inner loop to retry the request\n",
        "                else: # No rate limit error, break the retry loop for other GraphQL errors\n",
        "                     break\n",
        "                continue # Continue to the next retry attempt if rate limited\n",
        "\n",
        "            association = data['data']['repository']['pullRequest']['authorAssociation']\n",
        "            return association\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Request error for PR {pr_number} in {repo_owner}/{repo_name}: {e}\")\n",
        "            time.sleep(5 * (attempt + 1)) # Exponential backoff\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred for PR {pr_number} in {repo_owner}/{repo_name}: {e}\")\n",
        "            break # Don't retry for unexpected errors\n",
        "\n",
        "    return None # Return None if all retries fail\n",
        "\n",
        "\n",
        "# Prepare data: Ensure 'repo_url' and 'number' are available in metrics\n",
        "# You might need to merge with the original pull_request DataFrame if these columns were dropped\n",
        "if 'repo_url' not in metrics.columns or 'number' not in metrics.columns:\n",
        "     print(\"Warning: 'repo_url' or 'number' not found in metrics. Merging with original pull_request data.\")\n",
        "     # Assuming original pull_request is available\n",
        "     metrics = pd.merge(metrics, pull_request[['id', 'repo_url', 'number']], left_on='pr_id', right_on='id', how='left', suffixes=('', '_original'))\n",
        "     metrics = metrics.drop(columns=['id_original'], errors='ignore') # Drop duplicate id column\n",
        "\n",
        "\n",
        "# Extract repo owner and name from repo_url\n",
        "def extract_repo_details(repo_url):\n",
        "    try:\n",
        "        parts = repo_url.split('/')\n",
        "        owner = parts[-2]\n",
        "        name = parts[-1]\n",
        "        return owner, name\n",
        "    except Exception:\n",
        "        return None, None\n",
        "\n",
        "metrics[['repo_owner', 'repo_name']] = metrics['repo_url'].apply(lambda url: pd.Series(extract_repo_details(url)))\n",
        "\n",
        "\n",
        "# Apply the function to fetch author association for each PR\n",
        "# This can be slow due to API calls. Consider applying to a subset for testing.\n",
        "# Ensure TEST_MODE is handled if you want to limit API calls\n",
        "if 'TEST_MODE' in globals() and TEST_MODE:\n",
        "    print(\"Running in TEST_MODE, applying to a subset.\")\n",
        "    # Apply to the current subset of metrics\n",
        "    metrics['authorAssociation'] = metrics.apply(\n",
        "        lambda row: get_author_association(row['repo_owner'], row['repo_name'], row['number'], GH_TOKEN),\n",
        "        axis=1\n",
        "    )\n",
        "else:\n",
        "     print(\"Running on the full dataset.\")\n",
        "     metrics['authorAssociation'] = metrics.apply(\n",
        "        lambda row: get_author_association(row['repo_owner'], row['repo_name'], row['number'], GH_TOKEN),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "\n",
        "# Map authorAssociation to isMember (1 for MEMBER/OWNER, 0 otherwise)\n",
        "metrics['isMember'] = metrics['authorAssociation'].apply(\n",
        "    lambda x: 1 if x in ['MEMBER', 'OWNER'] else (0 if x is not None else None) # Handle None from API errors\n",
        ")\n",
        "\n",
        "# Drop temporary columns used for API calls if they are not needed for further analysis\n",
        "metrics = metrics.drop(columns=['repo_owner', 'repo_name', 'authorAssociation'], errors='ignore')\n",
        "\n",
        "\n",
        "print(f\"Number of PRs after adding isMember: {len(metrics):,}\")\n",
        "\n",
        "print(\"‚úÖ Calculated isMember using GraphQL API.\")\n",
        "display(metrics[['isMember']].head())\n",
        "display(metrics['isMember'].value_counts(dropna=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding isMember: 288\n",
            "Running in TEST_MODE, applying to a subset.\n",
            "GraphQL errors for PR 1 in laurance18/cm3l-research: [{'type': 'NOT_FOUND', 'path': ['repository'], 'locations': [{'line': 3, 'column': 7}], 'message': \"Could not resolve to a Repository with the name 'laurance18/cm3l-research'.\"}]\n",
            "Number of PRs after adding isMember: 288\n",
            "‚úÖ Calculated isMember using GraphQL API.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     isMember\n",
              "285       0.0\n",
              "283       0.0\n",
              "279       1.0\n",
              "280       1.0\n",
              "270       1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-896498e8-4ece-43af-9d36-a3c7316a5e9d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isMember</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-896498e8-4ece-43af-9d36-a3c7316a5e9d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-896498e8-4ece-43af-9d36-a3c7316a5e9d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-896498e8-4ece-43af-9d36-a3c7316a5e9d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a83e5c2e-e46c-4a38-9795-8d947e025d18\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a83e5c2e-e46c-4a38-9795-8d947e025d18')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a83e5c2e-e46c-4a38-9795-8d947e025d18 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(metrics['isMember']\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"isMember\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5477225575051662,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "isMember\n",
              "1.0    166\n",
              "0.0    121\n",
              "NaN      1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>isMember</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GraphQL Errors Example for isMember**\n",
        "\n",
        "GraphQL errors for PR ...: [{'type': 'NOT_FOUND', ... 'message': \"Could not resolve to a Repository with the name 'owner/repo'.\"}]: These are error messages from the GitHub GraphQL API. The NOT_FOUND type means that the API could not find the specific resource you were requesting. In these cases, the message \"Could not resolve to a Repository with the name 'owner/repo'\" indicates that the repository specified in the API call (e.g., 'vals-ai/vals-sdk', 'ImSingingInTheRain/gpai-assessment') could not be found on GitHub. This could be because the repository was renamed, deleted, or is private and your token doesn't have access.\n",
        "\n",
        "\n",
        "GraphQL errors for PR ...: [{'type': 'NOT_FOUND', ... 'message': 'Could not resolve to a PullRequest with the number of XX.'}]: Similarly, this error indicates that the specific pull request number within the given repository could not be found. This might happen if the PR was closed and potentially deleted, or the number is incorrect for that repository."
      ],
      "metadata": {
        "id": "LPoWAdik39GX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. **commentsTotalCount:** The # of comments left on a PR\n",
        "\n",
        "\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "`commentsTotalCount` is obtained directly from the GitHub GraphQL API. For each pull request it queries the PR‚Äôs `comments` connection and records the `totalCount` field, which is the number of comment objects attached to that PR (including review comments, issue‚Äëstyle comments, and any other discussion entries).\n",
        "\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "Group the `pr_comments` DataFrame by `pr_id` (Pull Request ID). Each row in `pr_comments` represents a single comment.\n",
        "Count the number of rows within each group using `.size()`.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ac9ifXkVgLqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (rentrant code)\n",
        "metrics.drop(columns=['commentsTotalCount'], errors='ignore', inplace=True)\n",
        "\n",
        "print(f\"Number of PRs before adding commentsTotalCount: {len(metrics):,}\")\n",
        "\n",
        "# Count the number of Comments for the Pull Request, name the column what we want.\n",
        "pr_comments_count = pr_comments.groupby(['pr_id']).size().reset_index(name='commentsTotalCount')\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, pr_comments_count, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframe\n",
        "pr_comments_count = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['commentsTotalCount'] = metrics['commentsTotalCount'].fillna(0).astype(int)\n",
        "\n",
        "print(f\"Number of PRs after adding commentsTotalCount: {len(metrics):,}\")"
      ],
      "metadata": {
        "id": "2BNmsnGIFO9Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458b9930-b8dc-4731-9f72-49e869ba53cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding commentsTotalCount: 288\n",
            "Number of PRs after adding commentsTotalCount: 288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. **authorComments:** The # of comments left by the PR author\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "Query each PR‚Äôs comment data through the GitHub GraphQL API and then filter the comment list to keep only those whose `author.login` matches the PR author‚Äôs login.\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "Merges `pr_comments` with author information and counting comments where the comment author matches the PR author."
      ],
      "metadata": {
        "id": "LoBAgwxOgaJn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "322b4128",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69cb1f0e-de9f-4ba3-c155-54b61219538e"
      },
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['authorComments'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding authorComments: {len(metrics):,}\")\n",
        "\n",
        "# Filter comments to only include those made by the PR author\n",
        "# Need to merge with metrics to get the author_id for each pr_comment\n",
        "author_comments = pd.merge(pr_comments, metrics[['pr_id', 'user_id']], left_on='pr_id', right_on='pr_id', how='left')\n",
        "author_comments = author_comments[author_comments['user_id_x'] == author_comments['user_id_y']]\n",
        "\n",
        "# Count the number of author comments per pull request\n",
        "author_comments_count = author_comments.groupby(['pr_id']).size().reset_index(name='authorComments')\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, author_comments_count, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframes\n",
        "author_comments = None\n",
        "author_comments_count = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['authorComments'] = metrics['authorComments'].fillna(0).astype(int)\n",
        "\n",
        "print(f\"Number of PRs after adding authorComments: {len(metrics):,}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding authorComments: 288\n",
            "Number of PRs after adding authorComments: 288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. **reviewersComments:** The # of comments left by the reviewers who participate in the disucssion\n",
        "\n",
        "\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "Querying the `comments` edge of each PR via GraphQL (or the REST endpoint `GET /repos/{owner}/{repo}/issues/{pull_number}/comments`). Filtering out comments whose user.login equals the PR author‚Äôs login. Counting the remaining comments ‚Äì that number is the reviewerComments value.\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "Merges `pr_comments` with author information and counting comments where the comment author does not match the PR author.\n",
        "\n"
      ],
      "metadata": {
        "id": "0cC_Qh-DgvEJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "454479f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99218e86-7358-4c20-bfd3-96eb96b9df45"
      },
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['reviewersComments'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding reviewersComments: {len(metrics):,}\")\n",
        "\n",
        "# Filter comments to exclude those made by the PR author\n",
        "# Need to merge with metrics to get the author_id for each pr_comment\n",
        "reviewer_comments = pd.merge(pr_comments, metrics[['pr_id', 'user_id']], left_on='pr_id', right_on='pr_id', how='left')\n",
        "reviewer_comments = reviewer_comments[reviewer_comments['user_id_x'] != reviewer_comments['user_id_y']]\n",
        "\n",
        "# Count the number of reviewer comments per pull request\n",
        "reviewer_comments_count = reviewer_comments.groupby(['pr_id']).size().reset_index(name='reviewersComments')\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, reviewer_comments_count, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframes\n",
        "reviewer_comments = None\n",
        "reviewer_comments_count = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['reviewersComments'] = metrics['reviewersComments'].fillna(0).astype(int)\n",
        "\n",
        "print(f\"Number of PRs after adding reviewersComments: {len(metrics):,}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding reviewersComments: 288\n",
            "Number of PRs after adding reviewersComments: 288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. **reviewersTotalCount:** The # of developers who participate in the discussion (excluding author).\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "Calling the GraphQL endpoint for each PR,\n",
        "Requesting the `reviewers` (or `reviewRequests`) connection,\n",
        "Reading the `totalCount` field,\n",
        "Verifying that the author‚Äôs login is excluded (or simply using the `totalCount` as GitHub already excludes the author in the `reviewers` connection).\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "Calculates `reviewersTotalCount` by summing the counts of unique commenters from review comments (`reviewer_commenters`) and unique reviewers from reviews (`reviewers`) for each pull request after merging those counts together.\n",
        "\n"
      ],
      "metadata": {
        "id": "sDtcHmxxg9MP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b294946"
      },
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['reviewersTotalCount'], errors='ignore')\n",
        "\n",
        "# Extract user_id from the nested 'user' column in pr_review_comments\n",
        "pr_review_comments['user_id_from_user'] = pr_review_comments['user'].apply(lambda x: x.get('id') if isinstance(x, dict) else None)\n",
        "\n",
        "# Extract user_id from the nested 'user' column in pr_reviews\n",
        "pr_reviews['user_id_from_user'] = pr_reviews['user'].apply(lambda x: x.get('id') if isinstance(x, dict) else None)\n",
        "\n",
        "# Get author_id from metrics for merging\n",
        "metrics['author_id_from_author'] = metrics['user'].apply(lambda x: x.get('id') if isinstance(x, dict) else None)\n",
        "\n",
        "\n",
        "# Get unique reviewer IDs from review comments, excluding the author\n",
        "reviewer_comments_users = pd.merge(pr_review_comments, metrics[['pr_id', 'author_id_from_author']], left_on='pull_request_review_id', right_on='pr_id', how='left')\n",
        "reviewer_comments_users = reviewer_comments_users[reviewer_comments_users['user_id_from_user'] != reviewer_comments_users['author_id_from_author']]\n",
        "reviewer_comments_users = reviewer_comments_users.groupby(['pull_request_review_id'])['user_id_from_user'].nunique().reset_index(name='reviewer_commenters')\n",
        "\n",
        "\n",
        "# Get unique reviewer IDs from reviews, excluding the author\n",
        "review_users = pd.merge(pr_reviews, metrics[['pr_id', 'author_id_from_author']], left_on='pr_id', right_on='pr_id', how='left')\n",
        "review_users = review_users[review_users['user_id_from_user'] != review_users['author_id_from_author']]\n",
        "review_users = review_users.groupby(['pr_id'])['user_id_from_user'].nunique().reset_index(name='reviewers')\n",
        "\n",
        "# Merge the two dataframes to get unique users from both sources\n",
        "reviewers_total = pd.merge(reviewer_comments_users, review_users, left_on='pull_request_review_id', right_on='pr_id', how='outer').fillna(0)\n",
        "\n",
        "# Calculate the total number of unique reviewers\n",
        "reviewers_total['reviewersTotalCount'] = reviewers_total['reviewer_commenters'] + reviewers_total['reviewers']\n",
        "reviewers_total = reviewers_total.drop(columns=['reviewer_commenters', 'reviewers'])\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, reviewers_total, left_on='pr_id', right_on='pull_request_review_id', how='left')\n",
        "\n",
        "# Garbage Collect temporary dataframes\n",
        "reviewer_comments_users = None\n",
        "review_users = None\n",
        "reviewers_total = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['reviewersTotalCount'] = metrics['reviewersTotalCount'].fillna(0).astype(int)\n",
        "\n",
        "# Drop the temporary user_id and author_id columns\n",
        "pr_review_comments = pr_review_comments.drop(columns=['user_id_from_user'], errors='ignore')\n",
        "pr_reviews = pr_reviews.drop(columns=['user_id_from_user'], errors='ignore')\n",
        "metrics = metrics.drop(columns=['author_id_from_author', 'pull_request_review_id'], errors='ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. **repoAge:** Time interval between the repository creation time and PR creation time in days.\n",
        "\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "- Retrieve the creation timestamp of the repository (the time the repo was first created on GitHub).\n",
        "- Retrieve the creation timestamp of the pull request under study.\n",
        "- Compute the time interval between these two timestamps in days\n",
        "\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "\n",
        "Merging `pr_review_comments` and `pr_reviews` DataFrames with our `metrics` to link comments/reviews to PR authors.\n",
        "Filtering these merged DataFrames to exclude rows where the comment/review user_id matches the PR author's user_id.\n",
        "Grouping the filtered data by `pr_id`.\n",
        "Calculating the count of distinct user_id values (`.nunique()`) within each `pr_id` group for both filtered DataFrames.\n",
        "Merging these unique counts and summing them per `pr_id` to get the total unique non-author participants across review comments and reviews.\n",
        "\n"
      ],
      "metadata": {
        "id": "Bvwr_F_0h3p-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['repoAge'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding repoAge: {len(metrics):,}\")\n",
        "\n",
        "# Copy the Repository dataframe\n",
        "repos_temp = repos.copy()\n",
        "\n",
        "# Calculate repo_created_at for the repos_temp DataFrame\n",
        "# This part was missing in the previous logic as the original cell was interrupted\n",
        "repos_temp['repo_created_at'] = repos_temp.apply(lambda row: get_repo_created_at(row['url']), axis=1)\n",
        "\n",
        "# Drop repos where repo_created_at could not be retrieved\n",
        "repos_temp = repos_temp.dropna(subset=['repo_created_at'])\n",
        "\n",
        "\n",
        "# Merge the Dataframes using a left join to bring repo_created_at into metrics\n",
        "# Ensure we only merge the necessary columns to avoid duplicates like repo_created_at_x\n",
        "metrics = pd.merge(metrics, repos_temp[['repo_id', 'repo_created_at']], on='repo_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary dataframe\n",
        "repos_temp = None\n",
        "\n",
        "# Drop from Metrics any Repo without a repo created date after the merge\n",
        "# This might be redundant if merged_at is already checked, but good for safety\n",
        "metrics = metrics.dropna(subset=['repo_created_at'])\n",
        "\n",
        "# Calculate the Repo Age in Days (created_at - repo_created_at)\n",
        "# Ensure 'created_at' and 'repo_created_at' are in datetime format before calculation\n",
        "metrics['created_at'] = pd.to_datetime(metrics['created_at'], errors='coerce')\n",
        "metrics['repo_created_at'] = pd.to_datetime(metrics['repo_created_at'], errors='coerce')\n",
        "\n",
        "metrics = metrics.assign(repoAge=lambda x: (x['created_at'] - x['repo_created_at']).dt.days)\n",
        "\n",
        "# Drop the unnecessary Repo Created At column after calculating repoAge\n",
        "metrics = metrics.drop(columns=['repo_created_at'], errors='ignore')\n",
        "\n",
        "# Fill N/A values for repoAge with defaults\n",
        "metrics['repoAge'] = metrics['repoAge'].fillna(0).astype(int)\n",
        "\n",
        "print(f\"Number of PRs after adding repoAge: {len(metrics):,}\")\n"
      ],
      "metadata": {
        "id": "ZBVOYKNaFOcN",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06e722ee-3fce-4809-dd9a-ce4cf052818f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding repoAge: 288\n",
            "Requesting: https://api.github.com/repos/galshohat/student-manage-ex\n",
            "Repo: https://api.github.com/repos/galshohat/student-manage-ex; Created At: 2025-07-07T17:07:11Z\n",
            "Requesting: https://api.github.com/repos/hossain-khan/android-keep-alive\n",
            "Repo: https://api.github.com/repos/hossain-khan/android-keep-alive; Created At: 2024-08-31T13:15:08Z\n",
            "Requesting: https://api.github.com/repos/laurance18/cm3l-research\n",
            "Error during GitHub API request for https://api.github.com/repos/laurance18/cm3l-research: 404 Client Error: Not Found for url: https://api.github.com/repos/laurance18/cm3l-research\n",
            "Requesting: https://api.github.com/repos/sohamw03/knowledge_net\n",
            "Repo: https://api.github.com/repos/sohamw03/knowledge_net; Created At: 2025-02-07T21:11:11Z\n",
            "Requesting: https://api.github.com/repos/yasu-programming/test-todo-app\n",
            "Repo: https://api.github.com/repos/yasu-programming/test-todo-app; Created At: 2025-06-05T12:38:41Z\n",
            "Requesting: https://api.github.com/repos/zaur9/endless-siege-somnia\n",
            "Repo: https://api.github.com/repos/zaur9/endless-siege-somnia; Created At: 2025-07-29T12:56:37Z\n",
            "Requesting: https://api.github.com/repos/zihaddi/zihaddi\n",
            "Repo: https://api.github.com/repos/zihaddi/zihaddi; Created At: 2022-10-10T17:43:24Z\n",
            "Requesting: https://api.github.com/repos/AlanCoding/dispatcher\n",
            "Repo: https://api.github.com/repos/AlanCoding/dispatcher; Created At: 2025-01-25T03:59:10Z\n",
            "Requesting: https://api.github.com/repos/Ckrest/Full-Codebase-Context-Generator\n",
            "Repo: https://api.github.com/repos/Ckrest/Full-Codebase-Context-Generator; Created At: 2025-07-20T07:27:28Z\n",
            "Requesting: https://api.github.com/repos/Coolix99/powersmooth\n",
            "Repo: https://api.github.com/repos/Coolix99/powersmooth; Created At: 2025-05-12T10:28:37Z\n",
            "Requesting: https://api.github.com/repos/FAeN399/Hex_Card_Forge\n",
            "Repo: https://api.github.com/repos/FAeN399/Hex_Card_Forge; Created At: 2025-05-27T23:49:58Z\n",
            "Requesting: https://api.github.com/repos/KodaCaleb/dmshield\n",
            "Repo: https://api.github.com/repos/KodaCaleb/dmshield; Created At: 2023-11-14T17:19:24Z\n",
            "Requesting: https://api.github.com/repos/M7mdIG/m7mdig.github.io\n",
            "Repo: https://api.github.com/repos/M7mdIG/m7mdig.github.io; Created At: 2023-07-28T23:36:14Z\n",
            "Requesting: https://api.github.com/repos/MuhammadYacoub/MuhammadYacoub\n",
            "Repo: https://api.github.com/repos/MuhammadYacoub/MuhammadYacoub; Created At: 2021-09-15T08:50:16Z\n",
            "Requesting: https://api.github.com/repos/RYZENNAVI/rendering\n",
            "Repo: https://api.github.com/repos/RYZENNAVI/rendering; Created At: 2025-06-15T13:03:27Z\n",
            "Requesting: https://api.github.com/repos/SingularityfForce/ai-edge-gallery-exp-tracking\n",
            "Repo: https://api.github.com/repos/SingularityfForce/ai-edge-gallery-exp-tracking; Created At: 2025-06-07T13:48:12Z\n",
            "Requesting: https://api.github.com/repos/Trenton140/trenton140.github.io\n",
            "Repo: https://api.github.com/repos/Trenton140/trenton140.github.io; Created At: 2024-04-03T17:37:46Z\n",
            "Requesting: https://api.github.com/repos/VeepCream/docurift\n",
            "Repo: https://api.github.com/repos/VeepCream/docurift; Created At: 2025-06-05T04:29:31Z\n",
            "Requesting: https://api.github.com/repos/adamboy7/PyKHeX\n",
            "Repo: https://api.github.com/repos/adamboy7/PyKHeX; Created At: 2022-03-27T04:54:19Z\n",
            "Requesting: https://api.github.com/repos/ajaykrishna00-7/traffic-ai-vision-control\n",
            "Repo: https://api.github.com/repos/ajaykrishna00-7/traffic-ai-vision-control; Created At: 2025-06-22T15:22:18Z\n",
            "Requesting: https://api.github.com/repos/aledlb8/Bondrith\n",
            "Repo: https://api.github.com/repos/aledlb8/Bondrith; Created At: 2023-08-28T01:58:48Z\n",
            "Requesting: https://api.github.com/repos/alexormx/inventory_app\n",
            "Repo: https://api.github.com/repos/alexormx/inventory_app; Created At: 2025-03-02T22:31:02Z\n",
            "Requesting: https://api.github.com/repos/augustomorais/python-challenge\n",
            "Repo: https://api.github.com/repos/augustomorais/python-challenge; Created At: 2023-11-22T10:36:42Z\n",
            "Requesting: https://api.github.com/repos/bannerism/mcp-duckdbt\n",
            "Repo: https://api.github.com/repos/bannerism/mcp-duckdbt; Created At: 2025-06-02T16:46:51Z\n",
            "Requesting: https://api.github.com/repos/brent132/SOLO_CONQUEST\n",
            "Repo: https://api.github.com/repos/brent132/SOLO_CONQUEST; Created At: 2025-06-04T07:53:24Z\n",
            "Requesting: https://api.github.com/repos/ermolenkodev/Resume-Matcher\n",
            "Repo: https://api.github.com/repos/ermolenkodev/Resume-Matcher; Created At: 2025-06-15T10:58:39Z\n",
            "Requesting: https://api.github.com/repos/freiberg-roman/dotfiles\n",
            "Repo: https://api.github.com/repos/freiberg-roman/dotfiles; Created At: 2025-01-23T16:16:05Z\n",
            "Requesting: https://api.github.com/repos/geonidas6/dropmind\n",
            "Repo: https://api.github.com/repos/geonidas6/dropmind; Created At: 2025-07-05T01:45:01Z\n",
            "Requesting: https://api.github.com/repos/gotfox/companion-module-psn\n",
            "Repo: https://api.github.com/repos/gotfox/companion-module-psn; Created At: 2025-05-19T04:45:42Z\n",
            "Requesting: https://api.github.com/repos/jmhansan/jmhansan.github.io\n",
            "Repo: https://api.github.com/repos/jmhansan/jmhansan.github.io; Created At: 2024-12-16T21:37:40Z\n",
            "Requesting: https://api.github.com/repos/joaomortani/fiap-global-solutions\n",
            "Repo: https://api.github.com/repos/joaomortani/fiap-global-solutions; Created At: 2025-06-06T17:03:31Z\n",
            "Requesting: https://api.github.com/repos/johncoronado/show-pi\n",
            "Repo: https://api.github.com/repos/johncoronado/show-pi; Created At: 2025-05-15T06:32:39Z\n",
            "Requesting: https://api.github.com/repos/karthikjohnbabu/DjangoBlog\n",
            "Repo: https://api.github.com/repos/karthikjohnbabu/DjangoBlog; Created At: 2024-06-21T17:37:31Z\n",
            "Requesting: https://api.github.com/repos/kenarai/codrops-singularity-demo\n",
            "Repo: https://api.github.com/repos/kenarai/codrops-singularity-demo; Created At: 2025-03-07T07:55:24Z\n",
            "Requesting: https://api.github.com/repos/leopers/h8x-app\n",
            "Repo: https://api.github.com/repos/leopers/h8x-app; Created At: 2025-07-02T02:31:18Z\n",
            "Requesting: https://api.github.com/repos/shadowae/Starwars-Chart\n",
            "Repo: https://api.github.com/repos/shadowae/Starwars-Chart; Created At: 2023-07-19T05:58:38Z\n",
            "Requesting: https://api.github.com/repos/stephenkiilu/Regression\n",
            "Repo: https://api.github.com/repos/stephenkiilu/Regression; Created At: 2025-06-19T16:20:12Z\n",
            "Requesting: https://api.github.com/repos/tscircuit/jlcsearch\n",
            "Repo: https://api.github.com/repos/tscircuit/jlcsearch; Created At: 2024-11-01T18:45:34Z\n",
            "Requesting: https://api.github.com/repos/xunhuang/SAT\n",
            "Repo: https://api.github.com/repos/xunhuang/SAT; Created At: 2025-05-13T03:44:03Z\n",
            "Requesting: https://api.github.com/repos/yokoyamatoyou/kaigi\n",
            "Repo: https://api.github.com/repos/yokoyamatoyou/kaigi; Created At: 2025-06-19T01:07:56Z\n",
            "Requesting: https://api.github.com/repos/Borislav88888/88\n",
            "Repo: https://api.github.com/repos/Borislav88888/88; Created At: 2025-02-20T23:19:47Z\n",
            "Requesting: https://api.github.com/repos/Oggie26/Happy_FE\n",
            "Repo: https://api.github.com/repos/Oggie26/Happy_FE; Created At: 2025-07-30T07:22:31Z\n",
            "Requesting: https://api.github.com/repos/RamonaPrower/meow-v2\n",
            "Repo: https://api.github.com/repos/RamonaPrower/meow-v2; Created At: 2023-04-07T10:11:58Z\n",
            "Requesting: https://api.github.com/repos/Vladic20/Monad-MiniVerse\n",
            "Repo: https://api.github.com/repos/Vladic20/Monad-MiniVerse; Created At: 2025-02-28T17:27:44Z\n",
            "Requesting: https://api.github.com/repos/it-beard/evo-bot-go\n",
            "Repo: https://api.github.com/repos/it-beard/evo-bot-go; Created At: 2024-08-21T11:17:01Z\n",
            "Requesting: https://api.github.com/repos/tsutaj/statements-manager\n",
            "Repo: https://api.github.com/repos/tsutaj/statements-manager; Created At: 2020-09-08T17:55:23Z\n",
            "Requesting: https://api.github.com/repos/xanman1000/glowup2\n",
            "Repo: https://api.github.com/repos/xanman1000/glowup2; Created At: 2025-06-01T01:08:53Z\n",
            "Requesting: https://api.github.com/repos/cognition-workshop/software-project-blueprint\n",
            "Repo: https://api.github.com/repos/cognition-workshop/software-project-blueprint; Created At: 2025-04-02T18:46:53Z\n",
            "Requesting: https://api.github.com/repos/dcSpark/mcp-server-defillama\n",
            "Repo: https://api.github.com/repos/dcSpark/mcp-server-defillama; Created At: 2025-03-02T06:59:36Z\n",
            "Requesting: https://api.github.com/repos/giantswarm/appcatalog\n",
            "Repo: https://api.github.com/repos/giantswarm/appcatalog; Created At: 2019-05-16T08:30:22Z\n",
            "Number of PRs after adding repoAge: 287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. **state**: State of the pull request (MERGED or CLOSED).\n",
        "\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "In GitHub GraphQL (or REST) API, the response includes a field called state (or, equivalently, a Boolean merged flag). The value of that field can be one of three mutually‚Äëexclusive statuses:\n",
        "- MERGED (or merged = true)\tThe PR was successfully merged into the target branch.\n",
        "- CLOSED (or merged = false‚ÄØ&‚ÄØstate = CLOSED)\tThe PR was closed without being merged.\n",
        "- OPEN (or state = OPEN)\tThe PR was still open at the time the data were collected.\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "If the `merged_at` column for a pull request has a value (i.e., it's not `null`), it means the pull request was merged, and the state is set to `MERGED`.\n",
        "If the `merged_at` column is `null`, it means the pull request was closed without being merged, and the state is set to `CLOSED`.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qNQdfoY8iNBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['state'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding state: {len(metrics):,}\")\n",
        "\n",
        "# Set the State to MERGED or CLOSED\n",
        "metrics['state'] = metrics['merged_at'].apply(lambda x: 'MERGED' if x is not None else 'CLOSED')\n",
        "\n",
        "print(f\"Number of PRs after adding state: {len(metrics):,}\")"
      ],
      "metadata": {
        "id": "5Ftmm7qZlHbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52dbdba5-c5ff-44c1-e606-5b9ec4851528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding state: 287\n",
            "Number of PRs after adding state: 287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. **reviewTime**: Time taken to review the PR (in hours, floating point, no rounding).\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "`reviewtime` (in hours) = (PR Closed Timestamp - PR Creation Timestamp).\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "The difference between the `closed_at` and `created_at` timestamps and converting that duration into hours.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VzgXfZtoCjPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['reviewTime'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding reviewTime: {len(metrics):,}\")\n",
        "\n",
        "# Calculate the Review Time\n",
        "metrics['reviewTime'] = (metrics['closed_at'] - metrics['created_at']).dt.total_seconds() / 3600\n",
        "\n",
        "print(f\"Number of PRs after adding reviewTime: {len(metrics):,}\")"
      ],
      "metadata": {
        "id": "UM0zn7ZtCmdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project variables"
      ],
      "metadata": {
        "id": "1unf8guqcK2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. **repoLanguage:** Programming language of the repository (e.g., Python, PHP, TypeScript, Vue).\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "The number of stargazers that a repository has\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "Same approach\n",
        "\n",
        "\n",
        "18. **forkCount:** The # of forks that a repository has\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "\n",
        "19. **stargazerCount:** The # of stargazers that a repository has.\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A5lSM-5VimJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['repoLanguage', 'forkCount', 'stargazerCount'], errors='ignore')\n",
        "\n",
        "repos_temp = (repos.copy()\n",
        "                   .drop(columns=['license', 'repo_url', 'html_url', 'full_name'], errors='ignore')\n",
        "                   .rename(columns={'language': 'repoLanguage', 'forks': 'forkCount', 'stars': 'stargazerCount'}))\n",
        "\n",
        "# Group by ID and get the First Record\n",
        "repos_temp = repos_temp.groupby(['repo_id']).first().reset_index() # Add reset_index() to make repo_id a column again\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, repos_temp, left_on='repo_id', right_on='repo_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframe\n",
        "repos_temp = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['repoLanguage'] = metrics['repoLanguage'].fillna('other')\n",
        "metrics['forkCount'] = metrics['forkCount'].fillna(0).astype(int)\n",
        "metrics['stargazerCount'] = metrics['stargazerCount'].fillna(0).astype(int)"
      ],
      "metadata": {
        "id": "hEoTBBXjFOVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treatment variables"
      ],
      "metadata": {
        "id": "RV-ykVvwcSGJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. **With Copilot for PRs:** Whether or not a PR is generated by Copilot for PRs (binary)\n"
      ],
      "metadata": {
        "id": "zUDj9SFMjShm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (rentrant code)\n",
        "metrics = metrics.drop(columns=['reviewTime'], errors='ignore')\n",
        "\n",
        "# Was the PR created by Copilot\n",
        "metrics['With Copilot for PRs'] = metrics['agent'].apply(lambda x: 1 if x == 'copilot' else 0)"
      ],
      "metadata": {
        "id": "btn7vVCnjSTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outcome variables"
      ],
      "metadata": {
        "id": "iRzFbe-Acwbw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. **Review time (reviewTime):** Time interval between the PR creation time and closed time in hours\n"
      ],
      "metadata": {
        "id": "0Nzqcx6Yi6Uo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61c5c683",
        "collapsed": true
      },
      "source": [
        "# Make sure we don't crash because the columns already exist (rentrant code)\n",
        "metrics = metrics.drop(columns=['reviewTime'], errors='ignore')\n",
        "\n",
        "# Calculate review time in hours, handling potential NaT values\n",
        "metrics = metrics.assign(reviewTime=lambda x: (x['closed_at'] - x['created_at']).dt.total_seconds() / 3600)\n",
        "\n",
        "# Fill N/A values with defaults (e.g., for open PRs)\n",
        "metrics['reviewTime'] = metrics['reviewTime'].fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. **Is merged (state):** Whether or not a PR is merged (binary)\n"
      ],
      "metadata": {
        "id": "-QSkr74njEzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['isMerged'], errors='ignore')\n",
        "\n",
        "# If Merged_At is None, the PR was not merged, otherwise it was\n",
        "metrics['isMerged'] = metrics['merged_at'].apply(lambda x: 0 if x is None else 1)"
      ],
      "metadata": {
        "id": "fvl0rnKHbOwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Order in CSV (treatment_metrics.csv and control_metrics.csc)\n",
        "\n",
        "1. **repoLanguage**\n",
        "2. **forkCount**\n",
        "3. **stargazerCount**\n",
        "4. **repoAge**\n",
        "5. **state**\n",
        "6. **deletions**\n",
        "7. **additions**\n",
        "8. **changedFiles**\n",
        "9. **commentsTotalCount**\n",
        "10. **commitsTotalCount**\n",
        "11. **prExperience**\n",
        "12. **isMember**\n",
        "13. **authorComments**\n",
        "14. **reviewersComments**\n",
        "15. **reviewersTotalCount**\n",
        "16. **bodyLength**\n",
        "17. **prSize**\n",
        "18. **reviewTime**\n",
        "19. **purpose**\n"
      ],
      "metadata": {
        "id": "0-kgS2O2dL6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export to CSV"
      ],
      "metadata": {
        "id": "3z7NwYwGxxiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the Google Drive folder\n",
        "drive_path = \"/content/drive/MyDrive/AIDev_shared/\"\n",
        "\n",
        "# Ensure the directory exists (optional, but good practice)\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "# Define the desired order of columns for the output CSVs\n",
        "csv_order = ['repoLanguage',\n",
        "'forkCount',\n",
        "'stargazerCount',\n",
        "'repoAge',\n",
        "'state',\n",
        "'deletions',\n",
        "'additions',\n",
        "'changedFiles',\n",
        "'commentsTotalCount',\n",
        "'commitsTotalCount',\n",
        "'prExperience',\n",
        "'isMember',\n",
        "'authorComments',\n",
        "'reviewersComments',\n",
        "'reviewersTotalCount',\n",
        "'bodyLength',\n",
        "'prSize',\n",
        "'reviewTime',\n",
        "'purpose']\n",
        "\n",
        "# Split the metrics DataFrame into treatment (Copilot) and control (non-Copilot) based on the 'user' column\n",
        "# Ensure the 'user' column exists before splitting, although it won't be in the final CSV\n",
        "# If 'user' column is not in metrics at this point, we might need to reload or adjust previous steps\n",
        "try:\n",
        "    treatment_metrics_full = metrics[metrics['user'].astype(str).str.strip() == 'Copilot'].copy()\n",
        "    control_metrics_full = metrics[metrics['user'].astype(str).str.strip() != 'Copilot'].copy()\n",
        "except KeyError:\n",
        "    print(\"Error: 'user' column not found in metrics DataFrame. Please ensure it's included in previous steps.\")\n",
        "    # You might want to add a fallback or stop execution here\n",
        "    raise # Re-raise the exception if you can't proceed\n",
        "\n",
        "# Select and reorder columns for the treatment and control DataFrames\n",
        "treatment_metrics = treatment_metrics_full[csv_order]\n",
        "control_metrics = control_metrics_full[csv_order]\n",
        "\n",
        "# Define the file paths\n",
        "treatment_file_path = os.path.join(drive_path, \"treatment_metrics.csv\")\n",
        "control_file_path = os.path.join(drive_path, \"control_metrics.csv\")\n",
        "\n",
        "# Export to CSV\n",
        "treatment_metrics.to_csv(treatment_file_path, index=False)\n",
        "control_metrics.to_csv(control_file_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ Exported treatment metrics to: {treatment_file_path}\")\n",
        "print(f\"‚úÖ Exported control metrics to: {control_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov2O_pNGwy-3",
        "outputId": "dc625362-4e56-4cd3-8d40-65cdbb9555a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Exported treatment metrics to: /content/drive/MyDrive/AIDev_shared/treatment_metrics.csv\n",
            "‚úÖ Exported control metrics to: /content/drive/MyDrive/AIDev_shared/control_metrics.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1Ô∏è‚É£ Check where zeros appear\n",
        "metrics[['isCopilot', 'additions', 'deletions', 'changed_files', 'reviewers_total_count', 'prSize']].groupby('isCopilot').mean()\n",
        "\n",
        "# 2Ô∏è‚É£ Check how many missing values before filling\n",
        "metrics[['additions', 'deletions', 'changed_files', 'reviewers_total_count']].isna().sum()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "fptYUjX9E8ne",
        "outputId": "4dda9d66-5a2a-4ed7-a959-d95bc3739455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['isCopilot', 'changed_files', 'reviewers_total_count'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4198545443.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1Ô∏è‚É£ Check where zeros appear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'isCopilot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'additions'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deletions'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'changed_files'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reviewers_total_count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prSize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'isCopilot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 2Ô∏è‚É£ Check how many missing values before filling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'additions'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deletions'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'changed_files'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reviewers_total_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['isCopilot', 'changed_files', 'reviewers_total_count'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fourth**, Bot detection and filtering employed the methodology of Golzadeh‚ÄØet‚ÄØal. (2022)\n",
        "\n",
        "simple ‚Äúbot‚Äù username suffix check with a comprehensive, manually verified list of 527 bot accounts\n",
        "* groundtruthbots.csv - a list of bots from Golzadeh et al.\n"
      ],
      "metadata": {
        "id": "V8vXCVjGW1aV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AqXYcUmgxz1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fifth**, Adoption Trend (RQ1)\n",
        "\n",
        "* Counted occurrences of each marker tag; copilot:summary was the most frequent (13‚ÄØ231 instances).\n",
        "* Visualised cumulative PRs over time (Fig.‚ÄØ3) and proportion of PRs per repository (Fig.‚ÄØ4).\n"
      ],
      "metadata": {
        "id": "g4l6_AqBzYVI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CNLP973ZzYBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sixth**, Causal Inference (RQ2)\n",
        "\n",
        "### Propensity‚ÄëScore Estimation\n",
        "Logistic regression (treatment‚ÄØ=‚ÄØCopilot usage) on the 17 covariates.\n",
        "Estimated each PR‚Äôs probability of receiving the treatment (ps).\n",
        "### Weight Construction\n",
        "Inverse‚Äëprobability weights: 1/ps for treated, 1/(1‚Äëps) for control.\n",
        "### Entropy Balancing\n",
        "Applied the entropy‚Äëbalancing algorithm (equivalent to R‚Äôs ebalance) to adjust the raw weights so that the weighted means of all covariates matched exactly between groups.\n",
        "After balancing, absolute mean differences for every covariate were ‚â§‚ÄØ0.10 (Fig.‚ÄØ2).\n",
        "### Outcome Regression\n",
        "* Review time (continuous): weighted ordinary least squares (lm analogue) with only the treatment indicator. The coefficient gave the Average Treatment Effect on the Treated (ATT) of ‚Äë19.3‚ÄØh (p‚ÄØ‚âà‚ÄØ1.6‚ÄØ√ó‚ÄØ10‚Åª¬π‚Å∑).\n",
        "* Merge outcome (binary): weighted logistic regression (glm with logit link). The exponentiated treatment coefficient yielded an odds ratio of 1.57 (95‚ÄØ%‚ÄØCI‚ÄØ[1.35,‚ÄØ1.84],‚ÄØp‚ÄØ<‚ÄØ0.001).\n",
        "These two models answer RQ2.1 (review‚Äëtime reduction) and RQ2.2 (higher merge likelihood).\n"
      ],
      "metadata": {
        "id": "48T4d5AezoVx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The R Scripts\n",
        "The main difference between PMW_merge.R and PMW_review.R is:\n",
        "\n",
        "* PMW_merge.R includes the column isMerged, which indicates whether each pull request was merged (state == \"MERGED\"). This column is added to the modeling data and used in the analysis.\n",
        "* PMW_review.R does not include the isMerged column in its modeling data; it focuses only on review-related metrics.\n",
        "* Otherwise, both scripts process the same input data, use similar covariates, and prepare for causal inference analysis. The inclusion of isMerged in PMW_merge.R allows for analysis related to PR merge status, while PMW_review.R is focused on review characteristics."
      ],
      "metadata": {
        "id": "kNvRCCdDFmIf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5GN6LEJdGbVD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}